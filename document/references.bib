@Misc{kaggle.dataset.image_road,
  author       = {Sanad Alali},
  howpublished = {Accessed: 2025-11-24, <https://www.kaggle.com/datasets/sanadalali/satellite-images-for-road-segmentation>},
  title        = {Satellite Images for Road Segmentation},
  year         = {2025},
}

@Article{Ronneberger2015,
  author        = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  year          = {2015},
  month         = may,
  abstract      = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1505.04597},
  eprint        = {1505.04597},
  file          = {:Ronneberger2015 - U Net_ Convolutional Networks for Biomedical Image Segmentation.pdf:PDF:https\://arxiv.org/pdf/1505.04597v1},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Demir2018,
  author    = {Demir, Ilke and Koperski, Krzysztof and Lindenbaum, David and Pang, Guan and Huang, Jing and Basu, Saikat and Hughes, Forest and Tuia, Devis and Raskar, Ramesh},
  title     = {DeepGlobe 2018: A Challenge to Parse the Earth through Satellite Images},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1805.06561},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{github.unet,
  author       = {Tung Dinh},
  howpublished = {Accessed: 2025-11-28, <https://github.com/tsdinh442/road-extraction/blob/main>},
  title        = {Road Extraction from Satellite Images Using UNet},
  year         = {2023},
}

@Article{Ibtehaz2019,
  author        = {Ibtehaz, Nabil and Rahman, M. Sohel},
  journal       = {Neural Networks},
  title         = {MultiResUNet : Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation},
  year          = {2019},
  issn          = {0893-6080},
  month         = jan,
  pages         = {74--87},
  volume        = {121},
  abstract      = {In recent years Deep Learning has brought about a breakthrough in Medical Image Segmentation. U-Net is the most prominent deep network in this regard, which has been the most popular architecture in the medical imaging community. Despite outstanding overall performance in segmenting multimodal medical images, from extensive experimentations on challenging datasets, we found out that the classical U-Net architecture seems to be lacking in certain aspects. Therefore, we propose some modifications to improve upon the already state-of-the-art U-Net model. Hence, following the modifications we develop a novel architecture MultiResUNet as the potential successor to the successful U-Net architecture. We have compared our proposed architecture MultiResUNet with the classical U-Net on a vast repertoire of multimodal medical images. Albeit slight improvements in the cases of ideal images, a remarkable gain in performance has been attained for challenging images. We have evaluated our model on five different datasets, each with their own unique challenges, and have obtained a relative improvement in performance of 10.15%, 5.07%, 2.63%, 1.41%, and 0.62% respectively.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  date          = {2019-02-11},
  doi           = {10.1016/j.neunet.2019.08.025},
  eprint        = {1902.04049},
  file          = {:Ibtehaz2019 - MultiResUNet _ Rethinking the U Net Architecture for Multimodal Biomedical Image Segmentation.pdf:PDF:https\://arxiv.org/pdf/1902.04049v1},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {Elsevier BV},
}

@Article{Hou2021,
  author    = {Hou, Yuewu and Liu, Zhaoying and Zhang, Ting and Li, Yujian},
  journal   = {Sensors},
  title     = {C-UNet: Complement UNet for Remote Sensing Road Extraction},
  year      = {2021},
  issn      = {1424-8220},
  month     = mar,
  number    = {6},
  pages     = {2153},
  volume    = {21},
  doi       = {10.3390/s21062153},
  publisher = {MDPI AG},
}

@Article{KrithikaaliasAnbuDevi2022,
  author    = {Krithika alias AnbuDevi, M. and Suganthi, K.},
  journal   = {Diagnostics},
  title     = {Review of Semantic Segmentation of Medical Images Using Modified Architectures of UNET},
  year      = {2022},
  issn      = {2075-4418},
  month     = dec,
  number    = {12},
  pages     = {3064},
  volume    = {12},
  doi       = {10.3390/diagnostics12123064},
  publisher = {MDPI AG},
}

@Article{Mena2003,
  author    = {Mena, J.B.},
  journal   = {Pattern Recognition Letters},
  title     = {State of the art on automatic road extraction for GIS update: a novel classification},
  year      = {2003},
  issn      = {0167-8655},
  month     = dec,
  number    = {16},
  pages     = {3037--3058},
  volume    = {24},
  doi       = {10.1016/s0167-8655(03)00164-8},
  publisher = {Elsevier BV},
}

@Article{Chen2022,
  author    = {Chen, Ziyi and Deng, Liai and Luo, Yuhua and Li, Dilong and Marcato Junior, José and Nunes Gonçalves, Wesley and Awal Md Nurunnabi, Abdul and Li, Jonathan and Wang, Cheng and Li, Deren},
  journal   = {International Journal of Applied Earth Observation and Geoinformation},
  title     = {Road extraction in remote sensing data: A survey},
  year      = {2022},
  issn      = {1569-8432},
  month     = aug,
  pages     = {102833},
  volume    = {112},
  doi       = {10.1016/j.jag.2022.102833},
  publisher = {Elsevier BV},
}

@Article{Wang2016,
  author    = {Wang, Weixing and Yang, Nan and Zhang, Yi and Wang, Fengping and Cao, Ting and Eklund, Patrik},
  journal   = {Journal of Traffic and Transportation Engineering (English Edition)},
  title     = {A review of road extraction from remote sensing images},
  year      = {2016},
  issn      = {2095-7564},
  month     = jun,
  number    = {3},
  pages     = {271--282},
  volume    = {3},
  doi       = {10.1016/j.jtte.2016.05.005},
  publisher = {Elsevier BV},
}

@Article{Akhtarmanesh2024,
  author    = {Akhtarmanesh, Arezou and Abbasi-Moghadam, Dariush and Sharifi, Alireza and Yadkouri, Mohsen Hazrati and Tariq, Aqil and Lu, Linlin},
  journal   = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  title     = {Road Extraction From Satellite Images Using Attention-Assisted UNet},
  year      = {2024},
  issn      = {2151-1535},
  pages     = {1126--1136},
  volume    = {17},
  doi       = {10.1109/jstars.2023.3336924},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Jiangtao2025,
  author        = {Jiangtao, Wang and Ruhaiyem, Nur Intan Raihana and Panpan, Fu},
  title         = {A Comprehensive Review of U-Net and Its Variants: Advances and Applications in Medical Image Segmentation},
  year          = {2025},
  month         = feb,
  abstract      = {Medical images often exhibit low and blurred contrast between lesions and surrounding tissues, with considerable variation in lesion edges and shapes even within the same disease, leading to significant challenges in segmentation. Therefore, precise segmentation of lesions has become an essential prerequisite for patient condition assessment and formulation of treatment plans. Significant achievements have been made in research related to the U-Net model in recent years. It improves segmentation performance and is extensively applied in the semantic segmentation of medical images to offer technical support for consistent quantitative lesion analysis methods. First, this paper classifies medical image datasets on the basis of their imaging modalities and then examines U-Net and its various improvement models from the perspective of structural modifications. The research objectives, innovative designs, and limitations of each approach are discussed in detail. Second, we summarize the four central improvement mechanisms of the U-Net and U-Net variant algorithms: the jump-connection mechanism, residual-connection mechanism, 3D-UNet, and transformer mechanism. Finally, we examine the relationships among the four core enhancement mechanisms and commonly utilized medical datasets and propose potential avenues and strategies for future advancements. This paper provides a systematic summary and reference for researchers in related fields, and we look forward to designing more efficient and stable medical image segmentation network models based on the U-Net network.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2502.06895},
  eprint        = {2502.06895},
  file          = {:Jiangtao2025 - A Comprehensive Review of U Net and Its Variants_ Advances and Applications in Medical Image Segmentation.pdf:PDF:https\://arxiv.org/pdf/2502.06895v1},
  keywords      = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences},
  primaryclass  = {eess.IV},
  publisher     = {arXiv},
}

@Article{Kuang2020,
  author    = {Kuang, Zhuo and Deng, Xianbo and Yu, Li and Wang, Hongkui and Li, Tiansong and Wang, Shengwei},
  journal   = {Computer Methods and Programs in Biomedicine},
  title     = {Psi-Net: Focusing on the border areas of intracerebral hemorrhage on CT images},
  year      = {2020},
  issn      = {0169-2607},
  month     = oct,
  pages     = {105546},
  volume    = {194},
  doi       = {10.1016/j.cmpb.2020.105546},
  publisher = {Elsevier BV},
}

@Comment{jabref-meta: databaseType:bibtex;}
