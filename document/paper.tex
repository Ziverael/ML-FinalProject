\def\paperversiondraft{draft}
\def\paperversionnormal{normal}

% If the paper version is set to 'normal' mode keep it,
% otherwise set it to 'draft' mode.
\ifx\paperversion\paperversionnormal
\else
  \def\paperversion{draft}
\fi

\documentclass[acmsmall]{acmart}

\def\acmversionanonymous{anonymous}
\def\acmversionjournal{journal}
\def\acmversionnone{none}

\makeatletter
\if@ACM@anonymous
  \def\acmversion{anonymous}
\else
  \def\acmversion{journal}
\fi
\makeatother

\usepackage{colortbl}

% 'draftonly' environment
\usepackage{environ}
\ifx\paperversion\paperversiondraft
\newenvironment{draftonly}{}{}
\else
\NewEnviron{draftonly}{}
\fi

% Most PL conferences are edited by conference-publishing.com. Follow their
% advice to add the following packages.
%
% The first enables the use of UTF-8 as character encoding, which is the
% standard nowadays. The second ensures the use of font encodings that support
% accented characters etc. The mictotype package
% enables certain features 'to­wards ty­po­graph­i­cal per­fec­tion
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}

\usepackage{xargs}
\usepackage{xparse}
\usepackage{xifthen, xstring}
\usepackage{xspace}
\usepackage{marginnote}
\usepackage{etoolbox}
\usepackage[acronym,shortcuts]{glossaries}
\usepackage{amsmath}
\usepackage{thmtools} % required for autoref to lemmas
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{hyphenat}
\usepackage[shortcuts]{extdash}

\input{tex/setup.tex}
\input{tex/acm.tex}

\usemintedstyle{colorful}

% Newer versions of minted require the 'customlexer' argument for custom lexers
% whereas older versions require the '-x' to be passed via the command line.
\makeatletter
\ifcsdef{MintedExecutable}
{
  % minted v3
  \newminted[mlir]{tools/lexers/MLIRLexer.py:MLIRLexerOnlyOps}{mathescape}
  \newminted[xdsl]{tools/lexers/MLIRLexer.py:MLIRLexer}{mathescape, style=murphy}
  \newminted[lean4]{tools/lexers/Lean4Lexer.py:Lean4Lexer}{mathescape}
}
{
  \ifcsdef{minted@optlistcl@quote}
  {
    \newminted[mlir]{tools/lexers/MLIRLexer.py:MLIRLexerOnlyOps}{customlexer, mathescape}
    \newminted[xdsl]{tools/lexers/MLIRLexer.py:MLIRLexer}{customlexer, mathescape, style=murphy}
    \newminted[lean4]{tools/lexers/Lean4Lexer.py:Lean4Lexer}{customlexer, mathescape}
  }
  {
    \newminted[mlir]{tools/lexers/MLIRLexer.py:MLIRLexerOnlyOps -x}{mathescape}
    \newminted[xdsl]{tools/lexers/MLIRLexer.py:MLIRLexer -x}{mathescape, style=murphy}
    \newminted[lean4]{tools/lexers/Lean4Lexer.py:Lean4Lexer -x}{mathescape}
  }
}
\makeatother

% We use the following color scheme
%
% This scheme is both print-friendly and colorblind safe for
% up to four colors (including the red tones makes it not
% colorblind safe any more)
%
% https://colorbrewer2.org/#type=qualitative&scheme=Paired&n=4

\definecolor{pairedNegOneLightGray}{HTML}{cacaca}
\definecolor{pairedNegTwoDarkGray}{HTML}{827b7b}
\definecolor{pairedOneLightBlue}{HTML}{a6cee3}
\definecolor{pairedTwoDarkBlue}{HTML}{1f78b4}
\definecolor{pairedThreeLightGreen}{HTML}{b2df8a}
\definecolor{pairedFourDarkGreen}{HTML}{33a02c}
\definecolor{pairedFiveLightRed}{HTML}{fb9a99}
\definecolor{pairedSixDarkRed}{HTML}{e31a1c}

\createtodoauthor{grosser}{pairedOneLightBlue}
\createtodoauthor{authorTwo}{pairedTwoDarkBlue}
\createtodoauthor{authorThree}{pairedThreeLightGreen}
\createtodoauthor{authorFour}{pairedFourDarkGreen}
\createtodoauthor{authorFive}{pairedFiveLightRed}
\createtodoauthor{authorSix}{pairedSixDarkRed}

\newacronym{ir}{IR}{Intermediate Representation}

\graphicspath{{./images/}}

% Define macros that are used in this paper
%
% We require all macros to end with a delimiter (by default {}) to enusure
% that LaTeX adds whitespace correctly.
\makeatletter
\newcommand\requiredelimiter[2][########]{%
  \ifdefined#2%
    \def\@temp{\def#2#1}%
    \expandafter\@temp\expandafter{#2}%
  \else
    \@latex@error{\noexpand#2undefined}\@ehc
  \fi
}
\@onlypreamble\requiredelimiter
\makeatother

\newcommand\newdelimitedcommand[2]{
\expandafter\newcommand\csname #1\endcsname{#2}
\expandafter\requiredelimiter
\csname #1 \endcsname
}

\newdelimitedcommand{toolname}{Tool}

\usepackage{booktabs}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\usepackage[verbose]{newunicodechar}
\newunicodechar{₁}{\ensuremath{_1}}
\newunicodechar{₂}{\ensuremath{_2}}
\newunicodechar{∀}{\ensuremath{\forall}}
\newunicodechar{α}{\ensuremath{\alpha}}
\newunicodechar{β}{\ensuremath{\beta}}

% \circled command to print a colored circle.
% \circled{1} pretty-prints "(1)"
% This is useful to refer to labels that are embedded within figures.
\DeclareRobustCommand{\circled}[2][]{%
    \ifthenelse{\isempty{#1}}%
        {\circledbase{pairedOneLightBlue}{#2}}%
        {\autoref{#1}: \hyperref[#1]{\circledbase{pairedOneLightBlue}{#2}}}%
}

% listings don't write "Listing" in autoref without this.
\providecommand*{\listingautorefname}{Listing}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}

\begin{document}

%% Title information
\title[Road extraction with U-Net]{Road extraction from satellite images utilizing U-Net architecture}       %% [Short Title] is optional;
                                      %% when present, will be used in
                                      %% header instead of Full Title.
\subtitle{}                   %% \subtitle is optional


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.
\author{Krzysztof Jankowski}
\authornote{}          %% \authornote is optional;
                                      %% can be repeated if necessary
\orcid{}             %% \orcid is optional
\affiliation{
  \position{Student}
  \department{Department of Mathematics}              %% \department is recommended
  \institution{Wrocław University of Science and Technology}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{Wrocław}
  \state{Lower Silesia}
  \postcode{Post-Code1}
  \country{Poland}
}
\email{262290@student.pwr.edu}          %% \email is recommended


\begin{abstract}
% An abstract should consist of six main sentences:
%  1. Introduction. In one sentence, what’s the topic?
%  2. State the problem you tackle.
%  3. Summarize (in one sentence) why nobody else has adequately answered the research question yet.
%  4. Explain, in one sentence, how you tackled the research question.
%  5. In one sentence, how did you go about doing the research that follows from your big idea.
%  6. As a single sentence, what’s the key impact of your research?

% (http://www.easterbrook.ca/steve/2010/01/how-to-write-a-scientific-abstract-in-six-easy-steps/)

Accurate detection of road networks in satellite imagery is a fundamental task for geographic information systems, urban planning, and autonomous navigation. However, variability in lighting conditions, occlusions, and background complexity makes reliable road segmentation a challenging problem. In this paper, we investigate the use of the U-Net convolutional neural network, originally developed for biomedical image segmentation, for the task of road detection in satellite images. The proposed approach formulates road extraction as a pixel-wise semantic segmentation problem and leverages the characteristic encoder-decoder architecture with skip connections to preserve both contextual and spatial information. We train and evaluate the U-Net model on satellite imagery datasets and assess its performance using standard segmentation metrics. The results demonstrate that U-Net is capable of accurately identifying road structures despite visual noise and complex surroundings. These findings suggest that architectures initially designed for medical imaging can be effectively adapted to remote sensing applications. The study is limited to supervised learning on annotated datasets and does not address real-time performance or cross-dataset generalization.
\authorTwo{Add note about modified Unet}
\end{abstract}

% Only add ACM notes and keywords in camera ready version
% Drop citations and footnotes in draft and blind mode.
\ifx\acmversion\acmversionanonymous
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\fi
\ifx\acmversion\acmversionjournal
%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010257.10010293.10010294</concept_id>
       <concept_desc>Computing methodologies~Neural networks</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Neural networks}%% End of generated code

%% Keywords
%% comma separated list
\keywords{U-Net, satellite, road extraction, CNN}
\fi

%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}
Ten artykuł przeznaczony jest do analizy sieci U-Net będącej jedną z wariantów Convolution Neural Network oraz jej wykorzystaniu w celu wykrywania dróg na zdjęciach satelitarnych. Sieć ta szczególnie znana jest w zastosowaniach medycznych.
\authorSix{Do przepisania}
	
U-Net is a specialized convolutional neural network (CNN) originally designed for image segmentation, particularly in biomedical imaging, where precise delineation of structures like organs, tumors, or cells is essential. It was proposed in Ronneberge et la.\cite{Ronneberger2015}. Its name comes from the distinctive U-shaped architecture, which consists of two main pathways: a contracting path (encoder) that captures contextual information by progressively downsampling the image, and an expanding path (decoder) that reconstructs spatial details by upsampling back to the original image size. Fig.~\ref{fig:unet} This symmetrical design enables the U-Net to combine both high-level semantic information and fine-grained localization in the final pixel-wise segmentation map.

\begin{figure}[htp]
    \centering
    \includegraphics[width=12cm]{diagram}
    \caption{Diagram of U-net archtecture (from Ibtehaz et al. \cite{Ibtehaz2019})}
    \label{fig:unet}
\end{figure}

The contracting path comprises a series of convolutional layers with activation functions (e.g., ReLU) and pooling operations that reduce spatial dimensions while increasing feature depth. This effectively extracts hierarchical features from the input. At the bottom of the “U” lies the bottleneck, which contains the most abstract representation of the input features. The expanding path then employs up-convolutions (also known as transposed convolutions) to restore spatial resolution. Importantly, it utilizes skip connections from corresponding levels of the encoder to preserve spatial information that might otherwise be lost during downsampling. These skip connections concatenate high-resolution encoder feature maps with decoder features, thus improving localization accuracy in the segmentation output.

Z drguiej strony ciekawym przykładem do rozważenia może być \(\Psi\)-Net opisana et la. Kuang~\cite{Kuang2020} w celu predykcji intracerebral hemorrhage.
As shown in Fig.~\ref{fig:psinet}, the name goes from \(\Psi\)-shaped archtecture. The architecture is built upon the U-Net encoder-decoder framework but extends it by incorporating multi-slice input to capture spatial contextual information. Instead of a single slice, the network processes three consecutive slices—the target slice and its two adjacent slices. Since feature extraction is consistent across slices, the encoders share parameters, which both preserves contextual information and limits model complexity.

\begin{figure}[htp]
    \centering
    \includegraphics[width=12cm]{psinet}
    \caption{Diagram of \(\Psi\)-net archtecture}
    \label{fig:psinet}
\end{figure}


To enhance feature representation, \(\Psi\)-Net introduces attention mechanisms on both the encoding and decoding sides. On the encoding side, self-attention blocks replace the standard convolutional layers of U-Net, enabling the model to suppress irrelevant information and strengthen global feature extraction. These blocks leverage higher-level feature maps to generate attention weights for lower layers, inspired by residual attention learning, while avoiding excessive network depth.

On the decoding side, contextual-attention blocks are employed to integrate spatial context from neighboring slices and guide the model to focus on the target region, particularly along object boundaries. Unlike self-attention, which mainly captures intra-slice information, contextual attention utilizes inter-slice features to improve local detail restoration. Together, these attention mechanisms allow \(\Psi\)-Net to effectively balance global contextual modeling and precise boundary recovery.

Facilitating the \(\Psi\)-Net architecture for image path extraction presents several advantages. The multi-slice (or multi-context) input design allows the model to leverage spatial continuity, which is essential for identifying long, narrow, and potentially fragmented paths in high-resolution images. The use of shared encoders ensures consistent feature extraction while maintaining a manageable model size. Additionally, the self-attention mechanism within the encoder enhances the modeling of global features, aiding in the differentiation of paths from visually similar background elements. Meanwhile, the contextual-attention mechanism in the decoder enhances the recovery of local details, particularly along path boundaries and intersections. Collectively, these features promote improved path continuity and boundary accuracy compared to standard U-Net architectures.

However, \(\Psi\)-Net also has several limitations concerning path extraction tasks. The dependence on multi-context inputs adds complexity to data preparation and may hinder generalization when contextual information is either inconsistent or lacking. The implementation of attention mechanisms introduces additional computational demands and can lead to increased sensitivity in training based on hyperparameter selection. Furthermore, although \(\Psi\)-Net enhances segmentation quality, it does not explicitly impose topological constraints, which are crucial for maintaining path connectivity. Consequently, post-processing steps or topology-aware loss functions may still be necessary to achieve fully connected and graph-consistent path representations.

\vspace{.5em}
\noindent
Our contributions are:
\grosser{Always state your contributions explicitly: (A) this makes it
easy for the reader to understand what novelty is presented, and (B)
these contributions help you to focus. In particular, the objective of
the remaining paper should be to support the claims stated here.
}
\begin{itemize}
	\item Implement \(\Psi\)-Net for path extraction
	\item Implement dedicated for path extraction U-Net
  \item Train and compare results of those models (\autoref{sec:results})
\end{itemize}

\section{Our New Idea}
Firstly, we tested how good can be \(\Psi\)-Net in road extraction task in comparison to standard U-Net archtecture. W implementacji modelu \(\Psi\)-Net, trzymaliśmy się zdefiniowanej we wspomniany artykule architektury.
On the other hand, in comparison to the baseline U-Net architecture, the proposed dedicated U-Net introduces several structural enhancements aimed at improving the segmentation of thin and elongated objects, such as roads. One key modification is the reduction of encoder depth from four to three downsampling stages, which minimizes excessive spatial resolution loss in deeper layers and helps retain fine-grained structural details. Furthermore, the bottleneck incorporates dilated convolutions, effectively enlarging the receptive field without additional downsampling. This design allows the model to capture long-range contextual dependencies essential for maintaining road continuity while alleviating the fragmentation often encountered in standard U-Net configurations. 

The decoder employs straightforward upsampling followed by convolution instead of transposed convolutions, which decreases computational complexity and mitigates checkerboard artifacts. Additionally, dedicated U-Net features a more streamlined and task-oriented design compared to the baseline. The reduced parameter count results in lower computational expenses and faster convergence, while enhanced regularization at the bottleneck through increased dropout improves generalization. Unlike the more generic design of the baseline, which disperses dropout across multiple layers and aggressively downsamples feature maps, the modified architecture focuses on preserving spatial details and aggregating global context. Consequently, the proposed model is better suited for road extraction tasks, producing sharper boundaries and more continuous predictions, particularly in challenging areas with narrow or partially occluded road segments.


\section{Results}\label{sec:results}
Aby obrać punkt odniesienia skorzystano z implementacji U-net zaproponowaną przez Tung Dinh~\cite{github.unet}. Przetrenowaliśmy ten model oraz nasze implementacje na dwóch różnych zbiorach danych. Pierwszy z nich składał się ze 100 zdjęć satelitarnych oraz 1000 sztucznie wygenerowanych obrazków~\cite{kaggle.dataset.image_road}. Drugi zbrór to DeepGlobe 2018 Dataset~\cite{Demir2018} zawerający 6226 zdjęć satelitarnych.

Do ewaluowania wykorzystano 3 metryki. Pierwszą z nich było accuracy
\[
acccuracy=\frac{TP+TN}{N},
\]
where \(TP\) are true positive, \(TN\) true negative and \(N\) number of classified objects. Kolejna to Intersection over Union (IoU) which calculates the amount of overlapping area between two bounding boxes - predicted boundgin box and ground truth. The last one is Dice coefficient which is also similarity metric, but is more preferable in imbalanced datasets.

Training and evaluations provide us series of useful observatrions. Po pierwsze modele uzyskiwały lepsze wartości accuracy dla danych z DeepGlobe. Wartości dla nich w kolejnych krokach treningu oscylowały w przediale \((0.96,0.98)\), gdy dla zbioru z Kaggle wyniki były w przedziale \((0.9, 0.92)\). Przewagę widać także w metryce dice coefficient, choć tutaj nie ma wyraźnie wizulanej granicy między datasetami.  Ponadto lepsze wyniki również osiągały modele wykorzystujące binary-crossentropy jako funkcję straty, niż te, które obrały dice coefficient loss. Co ciekawe dotyczy to obu omawianych metryk.

Z Fig.~\ref{fig:metrics} zauważyć można zarówno w metryce dice coefficient oraz accuracy i iou coefficient dedicate U-Net nieznacznie pokonuje pozostałe dwa modele. Model bazowy pozstaje w tyle we wszystkich metrykach z wyłączeniem iou coefficient, dla którego uzyskuje lepsze wyniki, niż \(\Psi\)-Net. Obserwjąc stratę, widać, że model \(\Psi\)-Net zbiegał najbardziej niestabilinie. Wyniki na danych testowych ukazały analogiczne wartości jak w te obserwpwame w danych walidacyjnych. Przedstawiono je w tabeli Table~\ref{tab:test} Jednocześnie warto zauważyć jak znacząca jest różnica w czasie treningu. Kiedy czas treningu baseline wyniósł około 1h, trening dedicated U-Net 3h to trening \(\Psi\)-Net już 12 h. Uwzględniając wyniki metryk, zdaje się, że model \(\Psi\)-Net nie jest wart, aż takich kosztów, a przynajmniej bez rozważenia jakichś usprawnień.
\begin{figure}[htp]
    \includegraphics[width=6.5cm]{acc.png}
    \includegraphics[width=6.5cm]{dice.png}
    
    \includegraphics[width=6.5cm]{iou.png}
    \includegraphics[width=6.5cm]{loss.png}
    \caption{Validation metrics comparison for all three models with dice loss and DeepGlobe dataset. Those models are U-Net (blue, alias unet\_base\_1\_dice\_dg), dedicated U-Net (green, alias unet\_modified\_1\_dice\_dg), and \(\Psi\)-Net (red, psinet\_dice\_dg).}
    \label{fig:metrics}
\end{figure}

\begin{table}
\begin{tabular}{ |p{3cm}|p{3cm}|p{3cm}|p{3cm}|  }
\hline
\multicolumn{4}{|c|}{Test metrics} \\
\hline
Model& accuracy &dice & iou \\
\hline
U-Net & 0.9705 & 0.6242 &0.4775 \\
Dedicated U-Net & 0.9719 & 0.6521   & 0.505 \\
\(\Psi\)-Net & 0.971 & 0.6259 & 0.4765 \\
\hline
\end{tabular}
\caption{Test dataset metrics evaluation on trained models}
\label{tab:test}
\end{table}

Z Fig.~\ref{fig:preds} można mieć wątpliwości, który z modeli poradził sobie najlepiej. Z jednej strony baseline zdaje się najdokładniej znajdować drogi, jednak z drugiej strony sklasyfikował znacznie więcej przypadkowych obiektów jako fragmenty dróg. Ponadto linie dróg w jego przypadku są najgrubsze. Pozostałe dwa modele generowały cieńsze linie, jakby próbowały skupić się na szukaniu centerline dróg. Z tego porównania \(\Psi\)-Net wypadł najgorzej. Zdawał się bardzo oszczędny we wskazywaniu dróg.


\begin{figure}[htp]
    \centering
    \includegraphics[width=12cm]{comparisons.png}
    \caption{Porównanie rezultatów predykcji 3 różnych zdjęć satelitarnych z wykorzystaniem wytrenowanych modeli.}
    \label{fig:preds}
\end{figure}


\section{Related Work}
Automatic road extraction from satellite imagery has been an active area of research for several decades, with traditional approaches often relying on classical image processing and GIS-based techniques. Early works emphasized feature-based methods, incorporating edge detection, morphological operations, and contextual information to delineate road networks et la. Mena \cite{Mena2003}. Subsequent surveys highlighted the progression toward machine learning and deep learning approaches, which offer superior accuracy and adaptability to complex urban and rural environments \cite{Wang2016}, \cite{Chen2022}.

Recent developments have centered on convolutional neural network (CNN) architectures adapted for semantic segmentation tasks. The U-Net model introduced by Ronneberger et al. \cite{Ronneberger2015} demonstrated that a symmetric encoder-decoder structure with skip connections allows precise localization while effectively utilizing limited annotated data. Extensions and modifications of U-Net, including MultiResU-Net \cite{Ibtehaz2019}, C-U-Net \cite{Hou2021}, and attention-assisted U-Net variants \cite{Akhtarmanesh2024}, have been proposed to enhance feature representation and mitigate challenges such as scale variation and occlusions in remote sensing imagery. Different approachs of extending by multiple encoders, U-net networks and 3D U-nets were reviewed et la. Jiangtao\cite{Jiangtao2025}.

\section{Conclusion}
W pracy przeanalizowano potencjalne możliwości wykorzystania architektury U-Net w celu road recognition. Zaproponowano podstawowy model z modyfikowanymi ilościami neurownów oraz redukcjami nadmiarowych warstw. Postanowiono również zbadać model \(\Psi\)-Net w tym zastosowaniu. Przetestowano modele na dwóch różnych zbiorach danych oraz z dwoma różnymi funkcjami straty: binary crossentropy oraz dice coefficient loss. Uzyskano dla proponowanych modeli accuracy 0.9719 i 0.971 oraz dice coefficient 0.6521 i 0.6529 dla Dedicated U-Net oraz \(\Psi\)-Net co było wynikami lepszymi, niż domyślny U-Net. Jednakże porównanie realnie uzyskanych masek dróg sugeruje, że modele wymagają dalszych usprawnień. W szególności \(\Psi\)-Net zdaje się nie być szczególnie zachęcającym modelem do trenowania, ze wzlgędu na fakt, że jego trening był 4 razy dłuższy, niż dla Dedicated U-Net.

%% Acknowledgments
\begin{acks} %% acks environment is optional
This paper was prepared as the final project for the Machine Learning course at Wrocław University of Science and Technology (2026).
\end{acks}

%% Bibliography
% \bibliographystyle{unsrt}
\bibliography{references}

\end{document}
